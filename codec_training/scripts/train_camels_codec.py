#!/usr/bin/env python3
"""Fine-tune an image codec on CAMELS map shards.

This harness loads shards generated by `prepare_camels_codec_data.py`, feeds
them through an AION image codec (typically the LegacySurvey tokenizer), and
optimizes reconstruction performance while keeping the workflow compatible with
`LocalCodecManager`.

The script focuses on single-modality image codecs (e.g. `LegacySurveyImage`)
and supports features commonly used in Jean-Zay experiments:
    * Mixed-precision training via PyTorch AMP.
    * Gradient accumulation for large effective batch sizes.
    * Cosine learning-rate scheduling with optional warm-up.
    * Checkpointing of the best validation run.

Example (assuming shards under `codec_training/data/illustris_codec`):

```bash
python codec_training/scripts/train_camels_codec.py \
  --train-manifest codec_training/data/illustris_codec/train/manifest.json \
  --val-manifest codec_training/data/illustris_codec/val/manifest.json \
  --codec-repo polymathic-ai/aion-base \
  --output-dir codec_training/checkpoints/camels_legacy_codec \
  --device cuda --epochs 50 --batch-size 32 --lr 3e-4 \
  --grad-accum 2 --scheduler cosine --warmup-epochs 5
```
"""

from __future__ import annotations

import argparse
import json
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Iterator, Sequence

import torch
from torch import nn
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR
from torch.utils.data import DataLoader, IterableDataset
from tqdm.auto import tqdm

from aion.modalities import LegacySurveyImage

from camels_aion.codec_manager import LocalCodecManager
from camels_aion.config import CAMELS_CODEC_BANDS


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--train-manifest", type=Path, required=True, help="Manifest JSON listing training shards.")
    parser.add_argument("--val-manifest", type=Path, required=True, help="Manifest JSON listing validation shards.")
    parser.add_argument("--codec-repo", type=str, required=True, help="Local path or Hugging Face repo containing the base codec.")
    parser.add_argument("--output-dir", type=Path, required=True, help="Directory where checkpoints and logs will be stored.")
    parser.add_argument("--bands", type=str, nargs="+", default=list(CAMELS_CODEC_BANDS), help="Band names matching the channel order in the shards.")
    parser.add_argument("--device", type=str, default="cuda", help="Compute device (`cuda`, `cuda:1`, or `cpu`).")
    parser.add_argument("--epochs", type=int, default=50, help="Number of training epochs.")
    parser.add_argument("--batch-size", type=int, default=32, help="Mini-batch size per optimizer step.")
    parser.add_argument("--grad-accum", type=int, default=1, help="Gradient accumulation steps before each optimizer update.")
    parser.add_argument("--lr", type=float, default=3e-4, help="Base learning rate.")
    parser.add_argument("--weight-decay", type=float, default=1e-4, help="Weight decay applied by AdamW.")
    parser.add_argument("--scheduler", type=str, choices=["none", "cosine"], default="cosine", help="LR scheduler type.")
    parser.add_argument("--warmup-epochs", type=int, default=5, help="Number of warm-up epochs (only for cosine scheduler).")
    parser.add_argument("--commitment-weight", type=float, default=0.0, help="Weight applied to quantizer commitment loss, if provided by the quantizer.")
    parser.add_argument("--amp", action="store_true", help="Enable mixed-precision training with autocast.")
    parser.add_argument("--log-every", type=int, default=50, help="Logging frequency in training steps.")
    parser.add_argument("--save-last", action="store_true", help="Also save the final epoch checkpoint in addition to the best one.")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for deterministic dataloader shuffling.")
    parser.add_argument("--num-workers", type=int, default=0, help="Number of worker processes for the dataloaders.")
    return parser.parse_args()


def load_manifest(manifest_path: Path) -> list[Path]:
    with open(manifest_path, "r", encoding="utf-8") as fh:
        manifest = json.load(fh)
    shard_names = manifest.get("shards", [])
    base_dir = manifest_path.parent
    return [base_dir / name for name in shard_names]


@dataclass
class CodecSample:
    flux: torch.Tensor
    labels: torch.Tensor | None


class CodecShardDataset(IterableDataset):
    """Stream codec training samples by iterating over prepared shard files."""

    def __init__(self, shards: Sequence[Path]) -> None:
        super().__init__()
        self.shards = list(shards)

    def __iter__(self) -> Iterator[CodecSample]:
        for shard_path in self.shards:
            payload = torch.load(shard_path, map_location="cpu")
            flux = payload["flux"]  # (B, C, H, W)
            labels = payload.get("labels")
            for idx in range(flux.shape[0]):
                yield CodecSample(flux=flux[idx], labels=None if labels is None else labels[idx])


def collate_samples(batch: list[CodecSample]) -> dict[str, torch.Tensor]:
    flux = torch.stack([sample.flux for sample in batch], dim=0)
    if batch[0].labels is not None:
        labels = torch.stack([sample.labels for sample in batch], dim=0)
    else:
        labels = None
    return {"flux": flux, "labels": labels}


def build_scheduler(optimizer: torch.optim.Optimizer, scheduler_name: str, epochs: int, warmup_epochs: int):
    if scheduler_name == "cosine":
        warm = max(0, min(warmup_epochs, epochs))
        stages: list[torch.optim.lr_scheduler._LRScheduler] = []
        milestones: list[int] = []
        if warm > 0:
            stages.append(LinearLR(optimizer, start_factor=0.1, total_iters=warm))
            milestones.append(warm)
        cosine_epochs = max(1, epochs - warm)
        stages.append(CosineAnnealingLR(optimizer, T_max=cosine_epochs, eta_min=0.0))
        if len(stages) == 1:
            return stages[0]
        return SequentialLR(optimizer, stages, milestones=milestones)
    return None


def save_checkpoint(path: Path, codec: nn.Module, optimizer: torch.optim.Optimizer, epoch: int, best_metric: float) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    payload = {
        "codec_state": codec.state_dict(),
        "optimizer_state": optimizer.state_dict(),
        "epoch": epoch,
        "best_metric": best_metric,
    }
    torch.save(payload, path)


def run_eval(codec: nn.Module, loader: DataLoader, device: torch.device, bands: Sequence[str], amp_enabled: bool) -> dict[str, float]:
    codec.eval()
    recon_loss = 0.0
    usage_accum = 0.0
    n_batches = 0
    criterion = nn.MSELoss()
    autocast_dtype = torch.float16 if amp_enabled and device.type == "cuda" else torch.float32

    with torch.no_grad():
        for batch in loader:
            flux = batch["flux"].to(device)
            modality = LegacySurveyImage(flux=flux, bands=list(bands))
            with torch.cuda.amp.autocast(enabled=amp_enabled and device.type == "cuda", dtype=autocast_dtype):
                embeddings = codec._encode(modality)
                quantized, _, usage = codec.quantizer.forward(embeddings)
                recon_modality = codec._decode(quantized, bands=list(bands))
                reconstructed = recon_modality.flux
                loss = criterion(reconstructed, flux)
            recon_loss += loss.item()
            usage_accum += float(usage.mean().item()) if torch.is_tensor(usage) else float(usage)
            n_batches += 1

    if n_batches == 0:
        return {"recon_loss": float("nan"), "codebook_usage": 0.0}
    return {
        "recon_loss": recon_loss / n_batches,
        "codebook_usage": usage_accum / n_batches,
    }


def main() -> None:
    args = parse_args()
    args.output_dir.mkdir(parents=True, exist_ok=True)

    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    torch.manual_seed(args.seed)

    train_shards = load_manifest(args.train_manifest)
    val_shards = load_manifest(args.val_manifest)

    train_dataset = CodecShardDataset(train_shards)
    val_dataset = CodecShardDataset(val_shards)

    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=collate_samples,
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=collate_samples,
    )

    codec_manager = LocalCodecManager(repo=args.codec_repo, device=device)
    codec = codec_manager._load_codec(LegacySurveyImage)
    codec = codec.to(device)

    optimizer = AdamW(codec.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = build_scheduler(optimizer, args.scheduler, args.epochs, args.warmup_epochs)
    scaler = torch.cuda.amp.GradScaler(enabled=args.amp and device.type == "cuda")

    best_val = float("inf")
    best_path = args.output_dir / "best_codec.pt"
    last_path = args.output_dir / "last_codec.pt"

    criterion = nn.MSELoss()
    autocast_dtype = torch.float16 if args.amp and device.type == "cuda" else torch.float32

    global_step = 0
    for epoch in range(1, args.epochs + 1):
        codec.train()
        optimizer.zero_grad(set_to_none=True)
        running_loss = 0.0
        running_usage = 0.0
        batch_count = 0

        progress = tqdm(train_loader, desc=f"Epoch {epoch}/{args.epochs}", leave=False)
        for batch in progress:
            flux = batch["flux"].to(device, non_blocking=True)
            modality = LegacySurveyImage(flux=flux, bands=list(args.bands))

            with torch.cuda.amp.autocast(enabled=args.amp and device.type == "cuda", dtype=autocast_dtype):
                embeddings = codec._encode(modality)
                quantized, commit_loss, usage = codec.quantizer.forward(embeddings)
                recon_modality = codec._decode(quantized, bands=list(args.bands))
                reconstructed = recon_modality.flux
                recon_loss = criterion(reconstructed, flux)
                total_loss = recon_loss + args.commitment_weight * commit_loss.mean()

            scaler.scale(total_loss / args.grad_accum).backward()

            if (global_step + 1) % args.grad_accum == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad(set_to_none=True)

            running_loss += recon_loss.item()
            running_usage += float(usage.mean().item()) if torch.is_tensor(usage) else float(usage)
            batch_count += 1
            global_step += 1

            if args.log_every > 0 and global_step % args.log_every == 0:
                avg_loss = running_loss / batch_count
                avg_usage = running_usage / max(1, batch_count)
                progress.set_postfix(loss=f"{avg_loss:.4f}", usage=f"{avg_usage:.3f}")

        progress.close()

        if scheduler is not None:
            scheduler.step()

        train_metrics = {
            "recon_loss": running_loss / max(1, batch_count),
            "codebook_usage": running_usage / max(1, batch_count),
        }
        val_metrics = run_eval(codec, val_loader, device, args.bands, args.amp)

        print(
            f"[Epoch {epoch:03d}] "
            f"train_loss={train_metrics['recon_loss']:.6f} "
            f"train_usage={train_metrics['codebook_usage']:.3f} "
            f"val_loss={val_metrics['recon_loss']:.6f} "
            f"val_usage={val_metrics['codebook_usage']:.3f} "
            f"lr={optimizer.param_groups[0]['lr']:.6e}"
        )

        metrics_path = args.output_dir / "metrics.jsonl"
        with open(metrics_path, "a", encoding="utf-8") as log_f:
            record = {
                "epoch": epoch,
                "train_loss": train_metrics["recon_loss"],
                "train_usage": train_metrics["codebook_usage"],
                "val_loss": val_metrics["recon_loss"],
                "val_usage": val_metrics["codebook_usage"],
                "learning_rate": optimizer.param_groups[0]["lr"],
            }
            log_f.write(json.dumps(record) + "\n")

        if val_metrics["recon_loss"] < best_val:
            best_val = val_metrics["recon_loss"]
            save_checkpoint(best_path, codec, optimizer, epoch, best_val)

    if args.save_last:
        save_checkpoint(last_path, codec, optimizer, args.epochs, best_val)


if __name__ == "__main__":
    main()
